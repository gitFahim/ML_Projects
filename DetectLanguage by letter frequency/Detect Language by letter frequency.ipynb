{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fcc5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f43af5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>ordered_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>etaoinsrhldcumfpgwybvkxjqz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>eaosrnidlctumpbgyívqóhfzjéáñxúüwk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german</td>\n",
       "      <td>enisratdhulcgmobwfkzvüpäßjöyqx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>french</td>\n",
       "      <td>esaitnrulodcmpévqfbghjàxèyêzçôùâûî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italian</td>\n",
       "      <td>eaionlrtscdupmvghfbqzòàùì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dutch</td>\n",
       "      <td>enatirodslghvkmubpwjczfxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turkish</td>\n",
       "      <td>aeinrlıdkmuytsboüşzgçhğvcöpfjwxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polish</td>\n",
       "      <td>iaeoznscrwyłdkmtpujlgębąhżśóćńfźvqx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>esperanto</td>\n",
       "      <td>aieonlsrtkjudmpvgfbcĝĉŭzŝhĵĥwyxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>swedish</td>\n",
       "      <td>eantrslidomgkvähfupåöbcjyxwzéq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>danish</td>\n",
       "      <td>enadtrslgiohmkvufbpøaejycéxqwèzüàóêçaaëä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>aeosrinmdutlcphvqgfbãzçjáéxóõêôàyíèú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>norwegian</td>\n",
       "      <td>erntsilakodgmvfupbhøjyaaæcwzx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>icelandic</td>\n",
       "      <td>anriestudhlgmkfhvoáthídjóbyæúöpéýcxwzq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hungarian</td>\n",
       "      <td>eatlnskomzrigáéydbvhjo:fupöócu:íúüxw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>slovak</td>\n",
       "      <td>aoesnitrvlkdmcupzyhjgfb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>finnish</td>\n",
       "      <td>enatrsildokgmvfaauphäcböjyxzw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>czech</td>\n",
       "      <td>oeantivlsrdkupímcházyjbřêéĉžýŝũgfúňwďóxť</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hawaiian</td>\n",
       "      <td>aiko’enuhlmâpôwêûî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maori</td>\n",
       "      <td>aiketonuhrmwgp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>latin</td>\n",
       "      <td>eituasrnomcpldqbgvfhxyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>irish</td>\n",
       "      <td>aihnretscoldgumbáfíéúópvjwykqz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>welsh</td>\n",
       "      <td>ayndreiloghwtfuscmbpâôy^w^jïêáqvî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gaelic</td>\n",
       "      <td>aihndercsgloutmbàfpo`ùéi`èó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>japanese</td>\n",
       "      <td>日一十二人大年会国三本長中五出事社市者月</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chinese</td>\n",
       "      <td>的一是不了在人有我他这中大来上国个到说们</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      language                           ordered_letters\n",
       "0      english                etaoinsrhldcumfpgwybvkxjqz\n",
       "1      spanish         eaosrnidlctumpbgyívqóhfzjéáñxúüwk\n",
       "2       german            enisratdhulcgmobwfkzvüpäßjöyqx\n",
       "3       french        esaitnrulodcmpévqfbghjàxèyêzçôùâûî\n",
       "4      italian                 eaionlrtscdupmvghfbqzòàùì\n",
       "5        dutch                 enatirodslghvkmubpwjczfxy\n",
       "6      turkish          aeinrlıdkmuytsboüşzgçhğvcöpfjwxq\n",
       "7       polish       iaeoznscrwyłdkmtpujlgębąhżśóćńfźvqx\n",
       "8    esperanto          aieonlsrtkjudmpvgfbcĝĉŭzŝhĵĥwyxq\n",
       "9      swedish            eantrslidomgkvähfupåöbcjyxwzéq\n",
       "10      danish  enadtrslgiohmkvufbpøaejycéxqwèzüàóêçaaëä\n",
       "11  portuguese      aeosrinmdutlcphvqgfbãzçjáéxóõêôàyíèú\n",
       "12   norwegian             erntsilakodgmvfupbhøjyaaæcwzx\n",
       "13   icelandic    anriestudhlgmkfhvoáthídjóbyæúöpéýcxwzq\n",
       "14   hungarian      eatlnskomzrigáéydbvhjo:fupöócu:íúüxw\n",
       "15      slovak                   aoesnitrvlkdmcupzyhjgfb\n",
       "16     finnish             enatrsildokgmvfaauphäcböjyxzw\n",
       "17       czech  oeantivlsrdkupímcházyjbřêéĉžýŝũgfúňwďóxť\n",
       "18    hawaiian                        aiko’enuhlmâpôwêûî\n",
       "19       maori                            aiketonuhrmwgp\n",
       "20       latin                   eituasrnomcpldqbgvfhxyk\n",
       "21       irish            aihnretscoldgumbáfíéúópvjwykqz\n",
       "22       welsh         ayndreiloghwtfuscmbpâôy^w^jïêáqvî\n",
       "23      gaelic               aihndercsgloutmbàfpo`ùéi`èó\n",
       "24    japanese                      日一十二人大年会国三本長中五出事社市者月\n",
       "25     chinese                      的一是不了在人有我他这中大来上国个到说们"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_df = pd.read_csv(\"ordered-letter-sequences.csv\", skiprows = 0, sep=',')\n",
    "lf_df.head(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc910953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(textfile):\n",
    "    with open(textfile, encoding=\"utf8\") as myfile:\n",
    "        content = myfile.readlines()\n",
    "    \n",
    "    all_letters ='esaitnrulodcmpévqfbghjàxèyêzçôùâûîøöœwkäßïëüæñ'\n",
    "    # initialize the dict with ordered entries for all letters, with each a value initialized to 0\n",
    "    dic ={letter: 0 for letter in all_letters}\n",
    "    total = 0\n",
    "    for line in content:\n",
    "        for letter in line:\n",
    "            letter = letter.lower()\n",
    "            if letter in all_letters:\n",
    "                total += 1\n",
    "                if letter in dic: dic[letter] += 1\n",
    "                else: dic[letter] = 0\n",
    "\n",
    "    # normalize\n",
    "    for letter in dic:\n",
    "        dic[letter] = dic[letter] / total\n",
    "    return dic\n",
    "\n",
    "textfile='eng.txt'\n",
    "\n",
    "text_lf_dict = process_file(textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddbbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.122573</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.069730</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.087707</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.080617</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.094401</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.071010</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.064332</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.028554</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.042000</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.071349</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency letter\n",
       "e   0.122573      e\n",
       "s   0.069730      s\n",
       "a   0.087707      a\n",
       "i   0.080617      i\n",
       "t   0.094401      t\n",
       "n   0.071010      n\n",
       "r   0.064332      r\n",
       "u   0.028554      u\n",
       "l   0.042000      l\n",
       "o   0.071349      o"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lf = pd.DataFrame.from_dict(text_lf_dict, orient='index', columns=['frequency'])\n",
    "text_lf['letter'] = text_lf.index\n",
    "text_lf.head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177b0b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etaionsrlhcdumpfgwbvykxqzj'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(text_lf[text_lf['frequency']>0].sort_values(by=['frequency'], ascending=False)['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3507394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate the Levenshtein distance matrix for two sequences\n",
    "# https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/ \n",
    "import numpy as np\n",
    "\n",
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    # print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0b88f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "4.0\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "print(levenshtein('bright','bright'))\n",
    "print(levenshtein('bright','freight'))\n",
    "print(levenshtein('bright','sleight'))\n",
    "print(levenshtein('bright','bride'))\n",
    "print(levenshtein('bright','plight'))\n",
    "print(levenshtein('bright','pride'))\n",
    "print(levenshtein('bright','donald duck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cc4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english :  11.0\n",
      "spanish :  23.0\n",
      "german :  25.0\n",
      "french :  24.0\n",
      "italian :  16.0\n",
      "dutch :  19.0\n",
      "turkish :  28.0\n",
      "polish :  26.0\n",
      "esperanto :  24.0\n",
      "swedish :  23.0\n",
      "danish :  31.0\n",
      "portuguese :  29.0\n",
      "norwegian :  22.0\n",
      "icelandic :  32.0\n",
      "hungarian :  30.0\n",
      "slovak :  22.0\n",
      "finnish :  22.0\n",
      "czech :  34.0\n",
      "hawaiian :  21.0\n",
      "maori :  22.0\n",
      "latin :  20.0\n",
      "irish :  21.0\n",
      "welsh :  26.0\n",
      "gaelic :  23.0\n",
      "japanese :  26.0\n",
      "chinese :  26.0\n",
      "We have a winner:  english\n"
     ]
    }
   ],
   "source": [
    "document_letter_sequence = ''.join(text_lf[text_lf['frequency']>0].sort_values(by=['frequency'], ascending=False)['letter'])\n",
    "# loop over the letter sequences in lf_df - for each language, determine levenshtein distance with document_letter_sequence\n",
    "best_score = 999\n",
    "best_matching_language = None\n",
    "for index, row in lf_df.iterrows():\n",
    "    ld = levenshtein(document_letter_sequence,row['ordered_letters'])\n",
    "    print(row['language'],': ',ld)\n",
    "    if ld < best_score:\n",
    "        best_score= ld\n",
    "        best_matching_language = row['language']\n",
    "print(\"We have a winner: \",best_matching_language)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff63d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enirtsalhuogkmcbdfpzävwüöyxjqßéñ\n",
      "english :  24.0\n",
      "spanish :  29.0\n",
      "german :  20.0\n",
      "french :  29.0\n",
      "italian :  25.0\n",
      "dutch :  24.0\n",
      "turkish :  28.0\n",
      "polish :  32.0\n",
      "esperanto :  27.0\n",
      "swedish :  22.0\n",
      "danish :  31.0\n",
      "portuguese :  32.0\n",
      "norwegian :  25.0\n",
      "icelandic :  32.0\n",
      "hungarian :  31.0\n",
      "slovak :  24.0\n",
      "finnish :  23.0\n",
      "czech :  33.0\n",
      "hawaiian :  27.0\n",
      "maori :  28.0\n",
      "latin :  23.0\n",
      "irish :  26.0\n",
      "welsh :  28.0\n",
      "gaelic :  26.0\n",
      "japanese :  32.0\n",
      "chinese :  32.0\n",
      "We have a winner:  german\n"
     ]
    }
   ],
   "source": [
    "def inspect_file(textfilename):\n",
    "      text_lf_dict = process_file(textfilename)\n",
    "      text_lf = pd.DataFrame.from_dict(text_lf_dict, orient='index', columns=['frequency'])\n",
    "      text_lf['letter'] = text_lf.index\n",
    "      document_letter_sequence = ''.join(text_lf[text_lf['frequency']>0].sort_values(by=['frequency'], ascending=False)['letter'])\n",
    "      print(document_letter_sequence)\n",
    "      # loop over the letter sequences in lf_df - for each language, determine levenshtein distance with document_letter_sequence\n",
    "      best_score = 999\n",
    "      best_matching_language = None\n",
    "      for index, row in lf_df.iterrows():        \n",
    "           ld = levenshtein(document_letter_sequence,row['ordered_letters'])\n",
    "           print(row['language'],': ',ld)\n",
    "           if ld == best_score:\n",
    "               best_matching_language = best_matching_language + ', '+row['language']\n",
    "           if ld < best_score:\n",
    "               best_score= ld\n",
    "               best_matching_language = row['language']\n",
    "      print(\"We have a winner: \",best_matching_language) \n",
    "    \n",
    "inspect_file('dictionary-de.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02e4bc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slok\n",
      "english :  23.0\n",
      "spanish :  30.0\n",
      "german :  26.0\n",
      "french :  31.0\n",
      "italian :  24.0\n",
      "dutch :  22.0\n",
      "turkish :  30.0\n",
      "polish :  33.0\n",
      "esperanto :  30.0\n",
      "swedish :  26.0\n",
      "danish :  36.0\n",
      "portuguese :  34.0\n",
      "norwegian :  26.0\n",
      "icelandic :  35.0\n",
      "hungarian :  34.0\n",
      "slovak :  21.0\n",
      "finnish :  25.0\n",
      "czech :  38.0\n",
      "hawaiian :  17.0\n",
      "maori :  13.0\n",
      "latin :  20.0\n",
      "irish :  27.0\n",
      "welsh :  31.0\n",
      "gaelic :  24.0\n",
      "japanese :  20.0\n",
      "chinese :  20.0\n",
      "We have a winner:  maori\n"
     ]
    }
   ],
   "source": [
    "inspect_file('sub001.txt')\n",
    "#Cannot detect Japanese or any asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c50f0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = '你好世界'\n",
    "\n",
    "query2 = '你好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07ccc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe5\\x93\\x88\\xe5\\x93\\x88'\n"
     ]
    }
   ],
   "source": [
    "print(u'哈哈'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e8b31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b95fd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cjk_detect(texts):\n",
    "    # korean\n",
    "    if re.search(\"[\\uac00-\\ud7a3]\", texts):\n",
    "        return \"korean\"\n",
    "    # japanese\n",
    "    if re.search(\"[\\u3040-\\u30ff]\", texts):\n",
    "        return \"japanese\"\n",
    "    # chinese\n",
    "    if re.search(\"[\\u4e00-\\u9FFF]\", texts):\n",
    "        return \"chinese\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e75fea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese\n",
      "japanese\n",
      "japanese\n",
      "korean\n",
      "japanese\n"
     ]
    }
   ],
   "source": [
    "texts = \"日産自動車、営業益45%減　前期下方修正\"\n",
    "print(cjk_detect(texts))\n",
    "# Traditional Chinese with Japanese hiragana\n",
    "texts = \"健康の油切 好吃の涼麵\"\n",
    "print(cjk_detect(texts))\n",
    "# Traditional Chinese with Japanese katakana punctuation\n",
    "texts = \"鐵腕・都鐸王朝（五）：文藝復興最懂穿搭的高富帥——亨利八世\"\n",
    "print(cjk_detect(texts))\n",
    "texts = \"이건 한국어가 아니야\"\n",
    "print(cjk_detect(texts))\n",
    "str = open('sub001.txt', 'r', encoding=\"utf8\").read()\n",
    "print(cjk_detect(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de08e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
